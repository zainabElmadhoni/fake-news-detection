{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIbJ-fLESkOd"
   },
   "source": [
    "In this notebook I applied two of the best know Deep Learning Models LSTM and CNN. I wanted to see if they can outperform the Machine Learning Algoriths I used in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kV_htjQsasN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import text\n",
    "from keras.layers import Dropout, Activation\n",
    "from keras.layers import Conv1D, Flatten\n",
    "from keras import metrics\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import GlobalMaxPooling1D, Input, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "id": "iuIjZ1tZti4a",
    "outputId": "487c9e51-933d-44b8-dc02-0e269625df61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   id        30000 non-null  int64         \n",
      " 1   text      30000 non-null  object        \n",
      " 2   date      30000 non-null  datetime64[ns]\n",
      " 3   source    30000 non-null  object        \n",
      " 4   likes     30000 non-null  int64         \n",
      " 5   retweets  30000 non-null  int64         \n",
      " 6   class     30000 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1288573860627877888</td>\n",
       "      <td>A medical group is warning that without action...</td>\n",
       "      <td>2020-07-29 20:35:23</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1288572426771554305</td>\n",
       "      <td>Covid-19 is now one of the leading causes of d...</td>\n",
       "      <td>2020-07-29 20:29:41</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>91</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1288570544481345538</td>\n",
       "      <td>JUST IN: More than 150,000 people have died in...</td>\n",
       "      <td>2020-07-29 20:22:12</td>\n",
       "      <td>SocialFlow</td>\n",
       "      <td>242</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1288566498995380232</td>\n",
       "      <td>This woman went to the hospital after breaking...</td>\n",
       "      <td>2020-07-29 20:06:08</td>\n",
       "      <td>SocialFlow</td>\n",
       "      <td>379</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1288562923904724992</td>\n",
       "      <td>President Trumpâ€™s tweet on dismantling an Obam...</td>\n",
       "      <td>2020-07-29 19:51:56</td>\n",
       "      <td>Twitter Media Studio</td>\n",
       "      <td>473</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  ... class\n",
       "0  1288573860627877888  ...     0\n",
       "1  1288572426771554305  ...     0\n",
       "2  1288570544481345538  ...     0\n",
       "3  1288566498995380232  ...     0\n",
       "4  1288562923904724992  ...     0\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"./twitter_data.pkl\")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYwFtenNIECd"
   },
   "source": [
    "Here I did the same thing as the previous notebook. I seperated the tweets related to the corona virus from the other tweets. In order to test the models on them while training it on the general tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "5y1hHpqEtn4U",
    "outputId": "9e991297-a02a-4862-d210-459ee221a712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3949 entries, 0 to 3948\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   id        3949 non-null   int64         \n",
      " 1   text      3949 non-null   object        \n",
      " 2   date      3949 non-null   datetime64[ns]\n",
      " 3   source    3949 non-null   object        \n",
      " 4   likes     3949 non-null   int64         \n",
      " 5   retweets  3949 non-null   int64         \n",
      " 6   class     3949 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(2)\n",
      "memory usage: 216.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26051 entries, 0 to 26050\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   id        26051 non-null  int64         \n",
      " 1   text      26051 non-null  object        \n",
      " 2   date      26051 non-null  datetime64[ns]\n",
      " 3   source    26051 non-null  object        \n",
      " 4   likes     26051 non-null  int64         \n",
      " 5   retweets  26051 non-null  int64         \n",
      " 6   class     26051 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "corona_tweets = list()\n",
    "for i in range(0, len(df)):\n",
    "    t=df['text'][i]\n",
    "    t=t.lower()\n",
    "    if t.find('corona')!=-1 or t.find('covid')!=-1: \n",
    "        corona_tweets.append([df['id'][i],\n",
    "                         df['text'][i],\n",
    "                         df['date'][i],\n",
    "                         df['source'][i],\n",
    "                         df['likes'][i],\n",
    "                         df['retweets'][i],\n",
    "                         df['class'][i]\n",
    "                         ])\n",
    "        df=df.drop(i)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df_ct= pd.DataFrame(corona_tweets,columns = ['id' , 'text', 'date','source','likes','retweets','class'])\n",
    "df_ct.info()   \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OFXsKF9utwLv"
   },
   "outputs": [],
   "source": [
    "#Shuffling the Data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_ct = df_ct.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9gRexvZtyTL"
   },
   "outputs": [],
   "source": [
    "y_train = df['class'].values\n",
    "y_test = df_ct['class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Se377CZ5uTrf"
   },
   "outputs": [],
   "source": [
    "X_train = df['text'].values\n",
    "X_test = df_ct['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsJnUUv0unvl"
   },
   "outputs": [],
   "source": [
    "#This class allows to vectorize a text corpus, by turning each text into either a sequence of integers \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waBk7-gCuyKy"
   },
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rnqeFlZvlWe"
   },
   "outputs": [],
   "source": [
    "#This function transforms a list of sequences into a 2D Numpy array of shape \n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=20, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=20, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "fI3ZVqKkvueM",
    "outputId": "fa1518ac-02c7-4006-fbb0-ee484749188d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 20, 20)            1291020   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 400)               673600    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 1,965,021\n",
      "Trainable params: 1,965,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=64551, output_dim=20, input_length=20))\n",
    "lstm_model.add(LSTM(400))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "48ZrmQ8Vvx-n",
    "outputId": "cee831b6-5334-4ec2-f81d-384019820b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "408/408 [==============================] - 69s 170ms/step - loss: 0.3268 - accuracy: 0.8546 - val_loss: 0.2474 - val_accuracy: 0.9017\n",
      "Epoch 2/10\n",
      "408/408 [==============================] - 69s 169ms/step - loss: 0.1013 - accuracy: 0.9641 - val_loss: 0.2656 - val_accuracy: 0.9149\n",
      "Epoch 3/10\n",
      "408/408 [==============================] - 69s 169ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.3449 - val_accuracy: 0.9109\n",
      "Epoch 4/10\n",
      "408/408 [==============================] - 69s 170ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.3163 - val_accuracy: 0.8979\n",
      "Epoch 5/10\n",
      "408/408 [==============================] - 69s 169ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.5025 - val_accuracy: 0.9091\n",
      "Epoch 6/10\n",
      "408/408 [==============================] - 69s 169ms/step - loss: 1.3401e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.9114\n",
      "Epoch 7/10\n",
      "408/408 [==============================] - 69s 169ms/step - loss: 1.9094e-05 - accuracy: 1.0000 - val_loss: 0.8293 - val_accuracy: 0.9109\n",
      "Epoch 8/10\n",
      "408/408 [==============================] - 69s 170ms/step - loss: 8.3794e-06 - accuracy: 1.0000 - val_loss: 0.9075 - val_accuracy: 0.9126\n",
      "Epoch 9/10\n",
      "408/408 [==============================] - 73s 179ms/step - loss: 4.6893e-06 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.9104\n",
      "Epoch 10/10\n",
      "408/408 [==============================] - 69s 169ms/step - loss: 2.7875e-06 - accuracy: 1.0000 - val_loss: 1.0499 - val_accuracy: 0.9124\n"
     ]
    }
   ],
   "source": [
    "history = lstm_model.fit(X_train_pad, y_train, epochs=10, batch_size=64, \n",
    "                        validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hg5WrsxPzLEC",
    "outputId": "27d469c7-e960-4b1b-c498-f1322c0020f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 3s 28ms/step - loss: 1.0499 - accuracy: 0.9124\n",
      "Test loss is 1.05 accuracy is 0.91 \n"
     ]
    }
   ],
   "source": [
    "acc = lstm_model.evaluate(X_test_pad, y_test)\n",
    "print(\"Test loss is {0:.2f} accuracy is {1:.2f} \".format(acc[0],acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsg3k7gdPPSi"
   },
   "source": [
    "As you can see, applying LSTM gave a test accuracy of 92%.<br>\n",
    "Next I will apply CNN to see if it can give us a better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "fM3U464qN9QT",
    "outputId": "214313fb-0de4-4efa-82d5-7a59cad6c233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 1000, 100)         6455100   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1000, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 998, 64)           19264     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 6,491,261\n",
      "Trainable params: 6,491,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "cnn_model.add(Embedding(64551, 100, input_length=1000))\n",
    "cnn_model.add(Dropout(0.2))\n",
    "cnn_model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(256))\n",
    "cnn_model.add(Dropout(0.2))\n",
    "cnn_model.add(Activation('relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.add(Activation('sigmoid'))\n",
    "cnn_model.summary()\n",
    "cnn_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tB8iUE-GO7ds"
   },
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_seq, maxlen=1000, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=1000, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "rwc3pKpgOthc",
    "outputId": "509a772c-f612-4d09-d727-c3e2715ebca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "408/408 [==============================] - 136s 332ms/step - loss: 0.3031 - acc: 0.8542 - val_loss: 0.3232 - val_acc: 0.8790\n",
      "Epoch 2/10\n",
      "408/408 [==============================] - 140s 343ms/step - loss: 0.0475 - acc: 0.9840 - val_loss: 0.2519 - val_acc: 0.9190\n",
      "Epoch 3/10\n",
      "408/408 [==============================] - 136s 333ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.2877 - val_acc: 0.9144\n",
      "Epoch 4/10\n",
      "408/408 [==============================] - 136s 332ms/step - loss: 1.2043e-04 - acc: 1.0000 - val_loss: 0.3429 - val_acc: 0.9015\n",
      "Epoch 5/10\n",
      "408/408 [==============================] - 136s 333ms/step - loss: 4.8127e-05 - acc: 1.0000 - val_loss: 0.3489 - val_acc: 0.9010\n",
      "Epoch 6/10\n",
      "408/408 [==============================] - 136s 333ms/step - loss: 3.1299e-05 - acc: 1.0000 - val_loss: 0.3661 - val_acc: 0.8969\n",
      "Epoch 7/10\n",
      "408/408 [==============================] - 139s 340ms/step - loss: 2.0375e-05 - acc: 1.0000 - val_loss: 0.3618 - val_acc: 0.8995\n",
      "Epoch 8/10\n",
      "408/408 [==============================] - 133s 327ms/step - loss: 1.4907e-05 - acc: 1.0000 - val_loss: 0.3884 - val_acc: 0.8931\n",
      "Epoch 9/10\n",
      "408/408 [==============================] - 133s 327ms/step - loss: 1.0197e-05 - acc: 1.0000 - val_loss: 0.3984 - val_acc: 0.8896\n",
      "Epoch 10/10\n",
      "408/408 [==============================] - 134s 329ms/step - loss: 7.6607e-06 - acc: 1.0000 - val_loss: 0.3971 - val_acc: 0.8924\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit(X_train_pad,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "8_JIkVelQmJC",
    "outputId": "d629b38c-d50f-4143-ccad-7c70f9ddfa15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 3s 26ms/step - loss: 0.3971 - acc: 0.8924\n",
      "Test loss is 0.40 accuracy is 0.89 \n"
     ]
    }
   ],
   "source": [
    "acc = cnn_model.evaluate(X_test_pad, y_test)\n",
    "print(\"Test loss is {0:.2f} accuracy is {1:.2f} \".format(acc[0],acc[1]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Part3. Deep Learning Methods (RNN-LSTM, CNN).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
